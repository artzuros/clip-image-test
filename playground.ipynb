{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RN50',\n",
       " 'RN101',\n",
       " 'RN50x4',\n",
       " 'RN50x16',\n",
       " 'RN50x64',\n",
       " 'ViT-B/32',\n",
       " 'ViT-B/16',\n",
       " 'ViT-L/14',\n",
       " 'ViT-L/14@336px']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clip.available_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\gunub\\.conda\\envs\\clip-image\\lib\\site-packages\\torch\\nn\\functional.py:5504: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = scaled_dot_product_attention(q, k, v, attn_mask, dropout_p, is_causal)\n"
     ]
    }
   ],
   "source": [
    "def generate_clip_embeddings(image_folder):\n",
    "    embeddings = {}\n",
    "    for image_name in os.listdir(image_folder):\n",
    "        image_path = os.path.join(image_folder, image_name)\n",
    "        \n",
    "        if not image_name.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "            continue\n",
    "        image = preprocess(Image.open(image_path)).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "        image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "        embeddings[image_name] = image_features.cpu().numpy()\n",
    "    \n",
    "    return embeddings\n",
    "image_folder = 'D:/C_Drive/Desktop/CS/clip-image-test/test'\n",
    "embeddings = generate_clip_embeddings(image_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('image_ (1).png', (1, 512))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First element of the dictionary\n",
    "list(embeddings.keys())[0] , (list(embeddings.values())[0]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('image_embeddings.pkl', 'wb') as f:\n",
    "    pickle.dump(embeddings, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load pkl file and see contents\n",
    "with open('test/image_embeddings.pkl', 'rb') as f:\n",
    "    embeddings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_ (100).png', 'image_ (39).png', 'image_ (40).png', 'image_ (41).png', 'image_ (42).png', 'image_ (43).png', 'image_ (44).png', 'image_ (45).png', 'image_ (46).png', 'image_ (47).png', 'image_ (48).png', 'image_ (49).png', 'image_ (50).png', 'image_ (51).png', 'image_ (52).png', 'image_ (53).png', 'image_ (54).png', 'image_ (55).png', 'image_ (56).png', 'image_ (57).png', 'image_ (58).png', 'image_ (59).png', 'image_ (60).png', 'image_ (61).png', 'image_ (62).png', 'image_ (63).png', 'image_ (64).png', 'image_ (65).png', 'image_ (66).png', 'image_ (67).png', 'image_ (68).png', 'image_ (69).png', 'image_ (70).png', 'image_ (71).png', 'image_ (72).png', 'image_ (73).png', 'image_ (74).png', 'image_ (75).png', 'image_ (76).png', 'image_ (77).png', 'image_ (78).png', 'image_ (79).png', 'image_ (80).png', 'image_ (81).png', 'image_ (82).png', 'image_ (83).png', 'image_ (84).png', 'image_ (85).png', 'image_ (86).png', 'image_ (87).png', 'image_ (88).png', 'image_ (89).png', 'image_ (90).png', 'image_ (91).png', 'image_ (92).png', 'image_ (93).png', 'image_ (94).png', 'image_ (95).png', 'image_ (96).png', 'image_ (97).png', 'image_ (98).png', 'image_ (99).png'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "clip-image",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
